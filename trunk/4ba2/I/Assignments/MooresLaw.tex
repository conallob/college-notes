% $Id$

\documentclass[a4paper,12pt]{article}

\setlength{\parindent}{0mm}
\setlength{\parskip}{7.5mm}

\begin{document}

\bibliographystyle{ieeetr}

\title{4BA2 \\ Assignment 1}

\author{Brian Brazil (02017610) brazilb@tcd.ie \\  Morgan McEvoy
(02460955) mcevoymj@tcd.ie \\ Conall O'Brien (01734351)
conallob@maths.tcd.ie \\ Eamon Phelan (02406390) phelanec@tcd.ie}

\maketitle

\section{What is Moore's Law}

\cite[The complexity for minimum component costs has increased at a rate
of roughly a factor of two per year ... Certainly over the short term
this rate can be expected to continue, if not to increase. Over the
longer term, the rate of increase is a bit more uncertain, although
there is no reason to believe it will not remain nearly constant for at
least 10 years. That means by 1975, the number of components per
integrated circuit for minimum cost will be 65,000. I believe that such
a large circuit can be built on a single wafer.]{a0}


Since Graham Moore first made this statement in 1965, there have been
many different interpretations of \emph{complexity} in the last 40
years. Depending on how \emph{complexity} is defined, Moore's Law,
\cite[as Caltech professor Carver Mead]{a1} christened it, has held true
for 40 years, but different interpretations can lead to the believe that
the exponention growth will not last more than another 20 years.


The oldest interpretation of Moore's Law, and Moore's original context,
was regarding the number of transistors fabircated on an individual 
integrated curcuit (IC). To date, this interpretation has remained true 
and many expect it to remain true for the forseeable future.


Over the years, particularly from the late 1970s, \emph{complexity} has 
also been considered to refer to IC physical dimensions, CPU clock 
speeds, RAM storage capacity. In most of these cases, empirical data has
proven that it has remained true thus far, however, some meanings,
particularly relating to the RAM storage are not growing as fast as
predicted, indicating there will be a time it will be an innaccurate
description.


Another common misconception which has appeared over the years is the
timescale of the growth. Moore's original statement was regarding the
growth over a 24 month time period. Some definitions of Moore's Law
inaccurately quote an 18 or 20 month time period.

\section{Problems Today}

In electronics in general denser units tend to be faster. The reason for
this
is that digital signals are not instantaneous, as electricity which
carries the
information is constrained by the speed of light. In fact electricity
travels
at only a fraction of the speed of light. Thus the shorter distance that
a
signal has to travel, the sooner it will arrive. This allows processors
to be
run at higher speeds and frequencies.

When Moore proposed his Law he said that chip density would double on a
regular
basis, thus implying that speed would also double. Problems arise
however when
smaller and smaller components start to exhibit different properties
than their
bigger versions. This can include such things as capacitive and
inductive effects, 
crosstalk, and antenna effects.

Capacitive effects can be seen in the wires interconnecting the various
parts
of a processor such as the Arithmetic Logic Unit, Floating Point Unit
and
Caches. Rather then the round wires to which you might be used to,
interconnect
\cite[wires are tall and thin]{b1}. They are thin in order to pack as many as
possible
in a small space and tall to increase their cross-sectional area, and
hence
reduce resistance. This has the potential to create a parallel plate
capacitor
between two wires which are beside each other at different voltage
levels.
This causes degradation and slows down the signal due to the
accumulation of
charge.

Inductive effects are somewhat similar to capacitive effect, however
they only
become a problem in sub-micron processes, for instance \cite[0.25 microns at
gigahertz frequencies]{b2}. Its effects are most apparent on high
frequency
wires that are relatively wide. \cite[One calculation puts the potential
impact to
delay time at 32\%]{b3}. 

A combination of inductance and capacitance can also cause transmission
line
crosstalk. This is where a signal on one line affects that of a nearby
line. In
the worst case this could cause a bit to flip and the wrong data to be
transmitted. This can be cut down on by methods such as keeping lines
short and
\cite[separating strong and weak signal lines]{b4}.

Antenna effects or plasma charging are caused by isolated electrical
points in
a \cite[processor becoming charged during the manufacturing process]{b5}. The
leaking
of this charge can cause degradation of parts of the gates, possibly
leading to
gate failure. \cite[This problem started to arise around 1994 and is not yet
fully
understood]{b6}.

Each of these effects requires effort on the part of chip designers to
take
them into account. The increased complexity of the electrical model of a
modern
CPU also requires more processing power to simulate. As can be seen
above with
inductive effects, some issues only come to light when dealing with
smaller
processes and higher frequencies. These require increasingly complex new
techniques such as \cite[]{b6} to be developed.

There are physical limits to silicon that we will not be able to go
past.
Beyond a certain minimal size a transistor would be affected by noise as
much
as its input and thus become useless for processing. Current estimates
from
Intel \cite[indicate that this is around 20 years away]{b8}. At that point a
new
technology would be required in order to maintain Moore's Law.

\section{Possible Alternatives: Future Trends}

Analyses have been performed of the theoretical limits of Moore's law
based on current silicon-based MOSFET technology; one such analysis was
published in the IEEE proceedings in 2003 \cite[]{e1}. The conclusion reached
was that while it may be technically feasible to produce switches at the
1nm level the heat dissipation problems that arise will prevent MOSFETS
from even approaching this density.

Therefore if we approach Moore's law from the definition of "the density
of transistors on a chip doubles every 1-2 years" then clearly according
to the ITRS roadmap (the roadmap the semiconductor industry sets out for
itself) \cite[]{e2} the limit will be approached well before 2021. 

Even if we assume current silicon MOSFET based technology however the
original formulation of Moore's law can still be upheld, ie. that the
complexity will increase by a factor of two. This can achieved by
splitting functionality at the chip or core level and improving both the
parallel technology and the speed of inter-core connections.

Indeed if we look at Intel's 2015 roadmap \cite[]{e3} we can see a steady
increase in the emphasis on parallelism as the architectures progress
from the single-pipeline 486 to the superscalar Pentium and the modern
hyper threading Pentium 4. If we look to future architectures, however,
we see a huge emphasis on parallelism with architectures like Intel's
Xscale and the IBM/Sony Cell architecture for use in the Playstation3
utilising a multi-core design with large numbers of subsidiary cores to
which to delegate processing, rather than all functionality being
integrated into a single processor core. This increase in the
parallelism rather than the density of the transistors will of course
require the processors to be able to take advantage of parallel code (or
inherent parallelism in the code) if it is to be of any use - which may
require a further emphasis on threading desktop software if the full
performance gains are to be achieved.

This increase in parallelism based on current technology will itself
require new technology to be developed for such purposes as
interconnection between the cores, which may prove a barrier;.optical
connections are being researched for such uses. According to Intel they
offer a possible solution to \cite[signal distortion, impedance mismatch,
cross-talk and electromagnetic interference that can arise as copper
interconnects reach higher and higher speeds."]{e4} The traditional
silicon based increases in chip density will continue for at least
another couple of generations as chip manufacturers implement chip
manufacturing processes already coming out of research and development
such as \cite[High-k Gate Dialectric Material]{e4}.

If we look beyond pure silicon based solutions there are a number of
possibilities being researched to help overcome the density barrier.
Carbon nanotubes can be used to either assemble transistors or channel
heat efficiently to allow increases in transistor density \cite[]{e4}.

There are also approaches to try and get beyond the theoretical limits
for a MOSFET switch. One option is \cite[single molecule transistors as have
recently been developed]{e5}. Single molecule transistors would obviously
be a huge step forward if they could be developed for use in the
semiconductor industry.

It is very difficult to forecast where nascent technologies will lead in
the course of the time until 2021 in a research heavy field like
semiconductor production. The industry is acutely aware of the physical
barriers it is approaching in chip manufacture and many avenues are
being explored. One thing that is definite however; with the huge
increase in funding by governments for nanotechnology: "In 1997,
government-funded research worldwide for nanotechnology came to around
$500 million. In 2003, it rose to $3.5 billion." new materials and
approaches on the scale the industry is now working at will certainly be
developed.

\section{Conslusion}

The general conclusion is that although Silicon is very popular within
the semiconductor industry at the moment, it will become a burden at
some point. Unless the industry adopt other technologies currently being
researched, Moore's Law will not remain true. If new technologies are
embraced, then there is not a currently concieved time when Moore's Law
will not continue to hold true.

\section{Bibliography}

\bibliography{MooresLaw}

\end{document}
